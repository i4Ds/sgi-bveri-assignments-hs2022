{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c6b40",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f10f19697935a18db955753fdc25539f",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b703d4d-0ab2-41cc-b8c4-3f42d2409dc8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "665d2c7903361b44cba522d3188df1c0",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Object-Detection\n",
    "\n",
    "Diese Übung basiert zum Teil auf: [https://pytorch.org/vision/stable/models.html#object-detection-instance-segmentation-and-person-keypoint-detection](https://pytorch.org/vision/stable/models.html#object-detection-instance-segmentation-and-person-keypoint-detection)\n",
    "\n",
    "\n",
    "## Lernziele\n",
    "\n",
    "- Object-Detection: Anwenden von Pre-Trained Modellen, Verstehen & Evaluieren der Outputs\n",
    "- COCO Format: Kennenlernen, Benutzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b675f9-dcc4-4f25-8d3a-681178d79ceb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb56c78cb143b3fa399cfc127b7561b2",
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Image \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836fca54-db85-48a7-b7cd-bbe396f6d032",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "693bbeb9a61403302a1fcc8b65575549",
     "grade": false,
     "grade_id": "parameters",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Parameter\n",
    "\n",
    "Definieren Sie den Pfad zu den Daten und extrahieren Sie die Daten.\n",
    "\n",
    "Für Colab-Nutzer: Führen Sie folgenden Code aus um die Daten zu lesen:\n",
    "\n",
    "\"\"\"\n",
    "%%bash\n",
    "\n",
    "!mkdir /content/data\n",
    "\n",
    "!wget https://github.com/i4Ds/sgi-bveri-assignments-hs2022/tree/main/assignments/03_object_detection/data.tar.gz -P /content/data/ \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb796a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddddc5f-ac43-45b4-9580-addd87edb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ROOT_PATH=$(pwd)\n",
    "tar -xvzf ${ROOT_PATH}/data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802fb9a2-5d8f-42c9-9835-e9ac81024e7b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3412a6a68a9f5aa6b49698b6aba396d4",
     "grade": false,
     "grade_id": "cell-edcdcb36b38944ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Pre-Trained _Faster R-CNN_\n",
    "\n",
    "In dieser Aufgabe werden wir ein vortrainiertes Object Detection Modell der Familie der _Faster R-CNNs_ einsetzen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb746ed-86b4-4203-808a-767ef046a91f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "787da9be362ff416f71530a48516b136",
     "grade": false,
     "grade_id": "cell-1ad02c611cb6b0d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Lesen Sie die folgenden Bilder ein mit `PIL.Image`. Schauen Sie die Bilder an und überlegen Sie sich wie gut Object-Detection funktionieren könnte.\n",
    "\n",
    "```\n",
    "DATA_PATH.joinpath(\"dog.jpg\")\n",
    "DATA_PATH.joinpath(\"ducks.jpeg\")\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84076903-a758-45e3-8c19-f33abeed0e81",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "601867454fd1da7d6544c16319203328",
     "grade": true,
     "grade_id": "cell-fe920be22a3799de",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7519ef56-3c75-4ab9-b9c9-74d87f9683a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6483b9a8517c1025d07e44c04d022dfe",
     "grade": false,
     "grade_id": "cell-b62acd4ad33420df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Laden Sie ein vortrainiertes Modell der _Faster R-CNN_ Familie von [torchvision](https://pytorch.org/vision/stable/models.html#object-detection-instance-segmentation-and-person-keypoint-detection). Eine Möglichkeit ist z.B. das `fasterrcnn_mobilenet_v3_large_320_fpn`, welches Resourcen-schonend ist. Wenn Sie bessere Performance möchten, können Sie gerne ein anderes wählen.\n",
    "\n",
    "```\n",
    "from torchvision.models.detection import (\n",
    "    fasterrcnn_mobilenet_v3_large_320_fpn,\n",
    "    FasterRCNN_MobileNet_V3_Large_320_FPN_Weights\n",
    "  )\n",
    "```\n",
    "\n",
    "Initialisieren Sie das Modell und setzten Sie es in den `eval` Mode. Setzten Sie `box_score_thresh` auf einen Wert zwischen 0.5 und 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed0a5e-95a0-4914-b1da-802f79724cd4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95f0a92d49a77c16f750d599a119ffc1",
     "grade": true,
     "grade_id": "cell-f757fea1c417faf8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b61f022-78fb-4b4f-a350-7645b20aba33",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56f07b1434125e6c5074f02430c31a55",
     "grade": false,
     "grade_id": "cell-bc2e5e0d131aa594",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Benutzen Sie Funktion `inference()` um Predictions für ein Bild zu generieren. Schauen Sie sich dazu folgendes Beispiel an: https://pytorch.org/vision/stable/models.html#object-detection-instance-segmentation-and-person-keypoint-detection\n",
    "\n",
    "Erstellen Sie danach Predictions für \"dog.jpg\" und inspizieren Sie den Output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e0874-33cd-4ddc-8322-fb8593293d1d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69e453cc1359bc6be8a5ebfcae0c0427",
     "grade": true,
     "grade_id": "cell-eafdeb3e614c1507",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(img, model, preprocess):\n",
    "    \"\"\" Inference on a single image\n",
    "        Args:\n",
    "            img: (C, H, W) torch.tensor\n",
    "            model: torchvision.models.detection.faster_rcnn.FasterRCNN\n",
    "            preprocess: function to pre-process image batch for the model\n",
    "            \n",
    "        Returns:\n",
    "            predictions: Dict with lists of object detections\n",
    "    \"\"\"\n",
    "    \n",
    "    image_batch = img.unsqueeze(0)\n",
    "    image_processed = preprocess(image_batch)\n",
    "    return model(image_processed)[0]\n",
    "    \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9c3ae-aef5-4918-8350-817d60d85af1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cb42a3009f14465170384349394189f",
     "grade": false,
     "grade_id": "cell-cbdc45817692565a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Visualisieren Sie die Predictions mit [torchvision.utils.draw_bounding_boxes](torchvision.utils.draw_bounding_boxes). Visualisieren Sie die Labels, sowie die Confidence-Scores der Predictions zusammen mit den Bounding-Boxes.\n",
    "\n",
    "Die Labels finden Sie in `weights.meta[\"categories\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331a863-9f13-4f64-b99d-7283ce457fb3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cc99d3a4f3758ca404a0f4124718b39",
     "grade": true,
     "grade_id": "cell-a1ff57e859223906",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "def draw_boxes(image, predictions, categories):\n",
    "    \"\"\" Draw Boxes from Predictions \n",
    "        Args:\n",
    "            image: The input image torch.tensor\n",
    "            predictions: Output of inference()\n",
    "            categories: List of category labels\n",
    "        Returns:\n",
    "            PIL.Image\n",
    "    \"\"\"\n",
    "    labels = [f\"{categories[i]} ({s * 100:.2f} %)\" for i, s in zip(predictions[\"labels\"], predictions[\"scores\"])]\n",
    "\n",
    "    box = draw_bounding_boxes(\n",
    "        image, boxes=predictions[\"boxes\"],\n",
    "        labels=labels, width=5,\n",
    "        colors=\"red\")\n",
    "    im = box.detach()\n",
    "    im = Image.fromarray(im.permute(1, 2, 0).numpy())\n",
    "    return im\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431c7d9-f1dd-447e-b421-e2a3b2517e91",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90ebb3eba698fb576c4f098e359f85be",
     "grade": false,
     "grade_id": "cell-d27167e6ad5bed75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Initialisieren Sie das Modell neu und wählen Sie einen tieferen Wert für [box_score_thresh](https://github.com/pytorch/vision/blob/main/torchvision/models/detection/faster_rcnn.py). \n",
    "\n",
    "Erstellen Sie danach Predictions für \"ducks.jpeg\".\n",
    "\n",
    "Visualisieren Sie wieder die Boxen.\n",
    "\n",
    "Berechnen Sie die IoU für die gefundenen Boxen. Sie können folgende Funktion verwenden [torchvision.ops.box_iou](https://pytorch.org/vision/stable/generated/torchvision.ops.box_iou.html#torchvision.ops.box_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c248fee-2e2a-444c-bc54-dde5d5aa2b8d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50b2b4ea0a4ba8f5090ee2626793071f",
     "grade": true,
     "grade_id": "cell-37ed2929b2adae96",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.ops import box_iou\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e5a81-9862-4085-855d-98800933c3a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "abc74dba9f6afa1ace91a7e79c9471bc",
     "grade": false,
     "grade_id": "cell-b266289993f18851",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Nun schauen wir uns die _activation maps_ vom Backbone-CNN an, welche in das RPN geht. Verwenden Sie dazu die folgende Funktion und inspizieren Sie die Shape der _activation map_.\n",
    "\n",
    "Schauen Sie sich die _acitvation maps_ von beiden Beispiel-Bildern an. Was stellen Sie fest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31691f6-2e5c-49fc-bfc6-6fd6c2491eca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82c71a13f0f470724f3cae894ace9d89",
     "grade": true,
     "grade_id": "cell-89997b51c70d45d9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def backbone(img, model, preprocess):\n",
    "    \"\"\" Get Features from the Backbone Network\n",
    "        Args:\n",
    "            img: (C, H, W) torch.tensor\n",
    "            model: torchvision.models.detection.faster_rcnn.FasterRCNN\n",
    "            preprocess: function to pre-process image batch for the model\n",
    "            \n",
    "        Returns:\n",
    "            predictions: Dict with lists of object detections\n",
    "    \"\"\"\n",
    "    image_batch = img.unsqueeze(0)\n",
    "    image_processed = preprocess(image_batch)\n",
    "    features = model.backbone(image_processed)\n",
    "    return features['0']\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff6dc6-304d-4260-b133-b9c78f51f5c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a931547d829fc376750e6b4489dec73",
     "grade": false,
     "grade_id": "cell-55115421343d1fa6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Nun schauen wir uns den Output des RPNs an. Vergleichen Sie wieder die beiden Bilder.\n",
    "\n",
    "Setzen Sie die Modell-Parameter: `rpn_score_thresh` und  `rpn_post_nms_top_n_test` und schauen Sie verschiedene Werte an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60120e6-e264-4ef9-8c4b-1c185ac47d7b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09d0d3b0b6c47ce1e4b9778d1e406864",
     "grade": true,
     "grade_id": "cell-f4bc3ac14d76daf4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rpn(img, model, preprocess):\n",
    "    \"\"\" Get Region Proposals\n",
    "        Args:\n",
    "            img: (C, H, W) torch.tensor\n",
    "            model: torchvision.models.detection.faster_rcnn.FasterRCNN\n",
    "            preprocess: function to pre-process image batch for the model\n",
    "            \n",
    "        Returns:\n",
    "            predictions: Dict with lists of object detections\n",
    "    \"\"\"\n",
    "    image_batch = img.unsqueeze(0)\n",
    "    image_processed = preprocess(image_batch)\n",
    "    \n",
    "    images, targets = model.transform(image_processed, targets=None)\n",
    "    features = model.backbone(image_processed)\n",
    "    proposals, proposal_losses = model.rpn(images, features, targets=targets)\n",
    "\n",
    "    original_image_sizes: List[Tuple[int, int]] = []\n",
    "    for img in image_batch:\n",
    "        val = img.shape[-2:]\n",
    "        torch._assert(\n",
    "            len(val) == 2,\n",
    "            f\"expecting the last two dimensions of the Tensor to be H and W instead got {img.shape[-2:]}\",\n",
    "        )\n",
    "        original_image_sizes.append((val[0], val[1]))\n",
    "    proposals = model.transform.postprocess([{'boxes': proposals[0]}], images.image_sizes, original_image_sizes)\n",
    "\n",
    "    return proposals\n",
    "\n",
    "\n",
    "def draw_proposals(image, proposals):\n",
    "    \"\"\" Draw Boxes from Predictions \n",
    "        Args:\n",
    "            image: The input image torch.tensor\n",
    "            predictions: Output of inference()\n",
    "            categories: List of category labels\n",
    "        Returns:\n",
    "            PIL.Image\n",
    "    \"\"\"\n",
    "\n",
    "    box = draw_bounding_boxes(\n",
    "        image, boxes=proposals,width=5,\n",
    "        colors=\"red\")\n",
    "    im = box.detach()\n",
    "    im = Image.fromarray(im.permute(1, 2, 0).numpy())\n",
    "    return im\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac192d46-1e1d-4f88-9f43-aa2461fe6cb1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "079aaccfc7b8ddb38eef755d22e7d3c8",
     "grade": false,
     "grade_id": "cell-2e8db955c61edeaf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Wir möchten nun unser Modell evaluieren. Dazu verwenden wir die \"pycocotools\". COCO ist ein Datensatz der Daten und Labels für verschiedene Computer Vision Tasks zur Verfügung stellt. Ausserdem definiert das COCO-Format wie Labels gespeichert werden und auch wie Modelle evaluiert werden.\n",
    "\n",
    "https://cocodataset.org/#explore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92695a8f-47dc-4e9f-a5e6-a62ba3e9d743",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27af5c3125a4546ba7b8ce74620c9fc6",
     "grade": false,
     "grade_id": "cell-4065bcfdd9de081b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb667aeb-fbd9-49a7-887d-1c406ff609d0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c115ab6635a9792c57055843cb8890e",
     "grade": false,
     "grade_id": "cell-615c0aad2bd8334e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "from torchvision.datasets import CocoDetection\n",
    "\n",
    "# We define the COCO-Dateset - The train split of the 2017 competition\n",
    "ds_coco = CocoDetection(\n",
    "    root=DATA_PATH.joinpath(\"coco_images\"),\n",
    "    annFile=DATA_PATH.joinpath('annotations/instances_train2017.json'))\n",
    "\n",
    "# We read the images that were prepared for this \n",
    "with open(DATA_PATH.joinpath(\"coco_images.txt\"), \"r\") as f:\n",
    "    coco_images_inventory = [int(x) for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9aa986-0a84-4206-926c-573e63f89943",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c920fbf0a57bda5a5455d1cabfbe8d0",
     "grade": false,
     "grade_id": "cell-cce3d5d8bb03a12d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Wir wählen nun ein Beispiel Bild aus und schauen uns das COCO-Format / die Annotationen für dieses Bild an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d2924-f325-4e47-a3ab-14be54f027d0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d19559513e1040837d9b5f5d0d20a446",
     "grade": true,
     "grade_id": "cell-cf43e929ada63136",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c293d-828d-4083-965e-23d4fa5d613c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea8ea08072ada990f04daed7d1709217",
     "grade": false,
     "grade_id": "cell-a18a1d533fa7519b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Wenden Sie nun das Modell auf das Beispiel-Bild an. Zeichnen Sie anschliessend die Detections ins das Bild mit der Funktion `draw_boxes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b448b-be25-4e62-a6e6-c89607587e4c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56be3e231debf8e38b7dfcbff6303e4b",
     "grade": true,
     "grade_id": "cell-ec37a1f1e382eab5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10709877-499b-41e6-9c0f-99d59f18671b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "199da2b47188d51b35fc8683c9354dee",
     "grade": false,
     "grade_id": "cell-4008435d2cbd05bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Zeichnen Sie nun die annotierten Boxen ein. Benutzen Sie dazu die Funktion `coco_annotations_as_predictions` zum Konvertieren der COCO-Annotationen für ein Bild in dasselbe Format wie die Predictions. Dann können Sie diese mit der Funktion `draw_boxes` visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b01e9d-300a-4f01-9bd8-2eee806190bc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7575be9f8893c134437393101652b6a9",
     "grade": true,
     "grade_id": "cell-46f0d262b1571d33",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.ops import box_convert\n",
    "\n",
    "def coco_annotations_as_predictions(coco_annotations):\n",
    "    \"\"\" Convert COCO Annotations to Predictions for Plotting \"\"\"\n",
    "    coco_as_predictions = {'boxes': [], 'labels': [], 'scores': []}\n",
    "    for i, coco_annotation in enumerate(coco_annotations):\n",
    "        coco_as_predictions['boxes'].append(coco_annotation['bbox'])\n",
    "        coco_as_predictions['labels'].append(coco_annotation['category_id'])\n",
    "        coco_as_predictions['scores'].append(1)\n",
    "\n",
    "    coco_as_predictions['boxes'] = box_convert(torch.tensor(coco_as_predictions['boxes']), in_fmt='xywh', out_fmt='xyxy')\n",
    "    return coco_as_predictions\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebbd186-7d0d-4c63-a8ee-81ff0251aa4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f0b1bde0a7cfa7bcecd526f3949b550",
     "grade": false,
     "grade_id": "cell-cfbdcb836740667e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Berechnen Sie nun IoU zwischen Detections und Annotationen, mit der Funktion `box_iou`. Achtung: die COCO-Annotationen sind im Format 'xywh', während die Predictions im Format 'xyxy' sind. Konvertieren Sie die COCO-Annotationen zu 'xyxy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911d47f-c124-4e93-8495-c092316f04fe",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a101648ed46c760e9db59b96c6571f2f",
     "grade": true,
     "grade_id": "cell-83d5a34c4af34c4c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f97c8-9c39-4ae5-9f14-1384e807d6b1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3eb29935eecd3b8f8733af15e45dc8de",
     "grade": false,
     "grade_id": "cell-90ac27e7da1ad838",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Predictions für mehrere Bilder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135bd3fe-0040-427d-954f-12a4b9a8b680",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "356cd66893b7c8ffdcf08c17c4084dab",
     "grade": false,
     "grade_id": "cell-2e0600159220b333",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_all = list()\n",
    "for coco_image_id in tqdm(coco_images_inventory):\n",
    "    #print(f\"{i}/{len(coco_images_inventory)}\")\n",
    "    coco_image, coco_annotations = ds_coco[ds_coco.ids.index(coco_image_id)]\n",
    "    image_torch = torch.tensor(np.array(coco_image)).permute(2, 0, 1)\n",
    "    images_all.append(image_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d954ae-0ca1-4af6-a87e-829eb8143841",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65b4ba01eee74c9b5161d729bd32e95f",
     "grade": false,
     "grade_id": "cell-e89bc3f61efa4d87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model = Model(weights=weights, box_score_thresh=0.8)\n",
    "model = model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions_all = list()\n",
    "    for image_torch in tqdm(images_all):\n",
    "        predictions = inference(image_torch, model, weights.transforms())\n",
    "        predictions_all.append(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074eef2-5f33-4f03-be90-956f7323d568",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69d36c03ac35b4f020fe082cbf26e115",
     "grade": false,
     "grade_id": "cell-25925a17b21fc6ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "We now convert the Predictions to the COCO-Format for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec829955-523b-448c-9b03-34f5b7f6733d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b30990fb31f2560f61e896600165ffba",
     "grade": false,
     "grade_id": "cell-ffeb8941db9867d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def convert_predictions_to_coco(predictions, image_id):\n",
    "    coco_predictions_for_eval = list()\n",
    "    for i,_ in enumerate(predictions['labels']):\n",
    "        boxes = list(box_convert(predictions['boxes'][i], out_fmt='xywh', in_fmt='xyxy').detach().numpy())\n",
    "        res = {\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": int(predictions['labels'][i]),\n",
    "            \"bbox\":boxes,\"score\": float(predictions['scores'][i]),\n",
    "            \"iscrowd\": None,\n",
    "            'area': float(predictions['boxes'][i][2] * predictions['boxes'][i][3])\n",
    "        }\n",
    "        coco_predictions_for_eval.append(res)\n",
    "    return coco_predictions_for_eval\n",
    "\n",
    "coco_predictions_for_eval = [convert_predictions_to_coco(x, image_id) for x, image_id in zip(predictions_all, coco_images_inventory)]\n",
    "coco_predictions_for_eval = list(itertools.chain.from_iterable(coco_predictions_for_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544dca1-bfde-4924-884c-60989f1d3ef0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fa29200dbe0611a6b0b46f017e6d844",
     "grade": false,
     "grade_id": "cell-e7292853642c1467",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coco_predictions_for_eval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00413667-9387-47a7-90d1-f6a9474813ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69ff701566a8cfba5933785d22c15f4c",
     "grade": false,
     "grade_id": "cell-f188fffbdd7263e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycocotools.cocoeval import COCOeval\n",
    "annType = 'bbox'\n",
    "annFile=DATA_PATH.joinpath('annotations/instances_train2017.json')\n",
    "coco=COCO(str(annFile))\n",
    "cocoDt=coco.loadRes(coco_predictions_for_eval)\n",
    "\n",
    "cocoEval = COCOeval(coco, cocoDt, annType)\n",
    "cocoEval.params.imgIds = coco_images_inventory\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b4600-8b10-4cb0-a0de-7c697346d70a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "962734bfd5ebf418ce1a822c011b4fa9",
     "grade": false,
     "grade_id": "cell-6b5c1f4c99436aff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Appendix - Prepare Data for Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653ae8f-81a2-4eb1-b44e-14da6e8093e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#wget https://drive.google.com/file/d/1t_l9uyBPfxSEzcajTk4a1TaQXzeRm9hw/view?usp=sharing -P `(pwd)`/data/coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b078a8d-b1c8-44a3-8b08-789823a44458",
   "metadata": {},
   "outputs": [],
   "source": [
    "annFile=DATA_PATH.joinpath('annotations/instances_train2017.json')\n",
    "coco=COCO(str(annFile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aca85a-28d4-4ecb-922e-c5add60d9b64",
   "metadata": {},
   "source": [
    "Get COCO data for specific categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba167cdb-2e44-45b6-87cd-4fdd920d4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "catIds = coco.getCatIds(catNms=['dog','cat']);\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "img = coco.loadImgs(imgIds)\n",
    "\n",
    "annIds = coco.getAnnIds(imgIds=imgIds)\n",
    "coco_images = coco.loadImgs(imgIds)\n",
    "\n",
    "for img in coco_images:\n",
    "    coco_image = Image.fromarray(io.imread(img['coco_url']))\n",
    "    coco_image.save(DATA_PATH.joinpath(f\"coco_images/{img['file_name']}\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75e166-a94b-422b-9814-560aa1591dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH.joinpath(\"coco_images.txt\"), \"w\") as f:\n",
    "    lines = [str(x) + \"\\n\" for x in imgIds[:-1]] + [str(imgIds[-1])]\n",
    "    f.writelines(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
